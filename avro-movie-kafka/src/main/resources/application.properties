topic_name=users
topic_partitions_num=3
topic_partions_replication_factor=1
server.port = 8003
bootstrap-servers = localhost:9092
schema.registry.url= http://localhost:8081

spring.main.allow-bean-definition-overriding = true

spring.kafka.bootstrap-servers = ${spring.embedded.kafka.brokers}
kafka.bootstrap-servers = ${spring.embedded.kafka.brokers}

spring.kafka.producer.properties.schema.registry.url= not-used
spring.kafka.producer.value-serializer = io.confluent.kafka.serializers.KafkaAvroSerializer
spring.kafka.producer.key-serializer = org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.group-id = mddarr-producer-id

spring.kafka.consumer.properties.schema.registry.url= not-used
spring.kafka.consumer.value-deserializer = io.confluent.kafka.serializers.KafkaAvroSerializer
spring.kafka.consumer.key-deserializer = io.confluent.kafka.serializers.KafkaAvroDeserializer
spring.kafka.consumer.group-id = mddarr-consumer-id
spring.kafka.auto.offset.reset = earliest

spring.kafka.producer.auto.register.schemas= true
spring.kafka.properties.specific.avro.reader= true




#spring:
#  kafka:
#    bootstrap-servers:
#      - localhost:9092
#    properties:
#      schema.registry.url: http://localhost:8081
#    consumer:
#      group-id: group_id
#      auto-offset-reset: latest
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
#      properties:
#        interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
#    producer:
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
#      properties:
#        interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
#    template:
#      default-topic:
logging:
  level:
    root: info